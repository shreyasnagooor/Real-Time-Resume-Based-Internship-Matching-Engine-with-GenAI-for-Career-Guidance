{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgruvCmLaptMuub8fiOaB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasnagooor/Real-Time-Resume-Based-Internship-Matching-Engine-with-GenAI-for-Career-Guidance/blob/main/%20Real-Time%20Resume-Based%20Internship%20Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efZtOdWWSVb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  Real-Time Resume-Based Internship Matching Engine with Gen AI for Career Guidance\n",
        "\n",
        "Welcome to the **Job Recommendation System**! This project matches job descriptions from internship data with resumes using natural language processing (NLP) techniques. By leveraging cosine similarity, it finds the most relevant job descriptions for given resumes, helping job seekers find their best-fit opportunities.\n",
        "\n",
        "> **Career Guidance**: For aspiring professionals in AI/ML, explore **[HackML](https://hackml.vercel.app/)** for resources and mentorship in your career journey!\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Overview](#overview)\n",
        "2. [Technologies Used](#technologies-used)\n",
        "3. [Data Preparation](#data-preparation)\n",
        "4. [Preprocessing](#preprocessing)\n",
        "5. [Model](#model)\n",
        "6. [Evaluation](#evaluation)\n",
        "7. [Visualization](#visualization)\n",
        "8. [Installation](#installation)\n",
        "9. [Usage](#usage)\n",
        "10. [Contributing](#contributing)\n",
        "11. [License](#license)\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This system is designed to recommend job descriptions based on the similarity between the text of resumes and job descriptions. It uses **Sentence Transformers** to convert text into embeddings, then calculates **cosine similarity** to rank job descriptions for each resume. The goal is to help job seekers identify the most relevant opportunities based on their resumes.\n",
        "\n",
        "---\n",
        "\n",
        "## Technologies Used\n",
        "\n",
        "- **Python 3.x**\n",
        "- **Libraries**:\n",
        "  - `pandas` – For data manipulation\n",
        "  - `numpy` – For numerical operations\n",
        "  - `re` – For regular expressions\n",
        "  - `nltk` – For text processing and tokenization\n",
        "  - `sentence-transformers` – For sentence embeddings and semantic similarity\n",
        "  - `scikit-learn` – For cosine similarity and model evaluation\n",
        "  - `seaborn` & `matplotlib` – For data visualization\n",
        "\n",
        "---\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "This project requires two datasets:\n",
        "1. **Internship Data**: Contains job descriptions for internships.\n",
        "2. **Resume Data**: Contains resumes to be matched with the job descriptions.\n",
        "\n",
        "### Required Columns:\n",
        "- **Internship Data (`df1`)**: `Cleaned_Job_Description`\n",
        "- **Resume Data (`df2`)**: `Cleaned_Text`\n",
        "\n",
        "Both datasets should be cleaned and preprocessed before use.\n",
        "\n",
        "---\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "The text data is cleaned and preprocessed through the following steps:\n",
        "1. **Cleaning**: Removing non-alphanumeric characters, numbers, and extra spaces.\n",
        "2. **Tokenization**: Breaking text into individual tokens (words).\n",
        "3. **Stopwords Removal**: Removing common, non-meaningful words (e.g., \"the\", \"is\").\n",
        "4. **Lemmatization**: Converting words to their root form (e.g., \"running\" → \"run\").\n",
        "\n",
        "Both job descriptions and resumes undergo this preprocessing before being used in the recommendation system.\n",
        "\n",
        "---\n",
        "\n",
        "## Model\n",
        "\n",
        "We use the **Sentence Transformer** model (`all-MiniLM-L6-v2`) to encode both the job descriptions and resumes into vector representations (embeddings). These embeddings are compared using **cosine similarity** to determine the degree of match between each resume and job description.\n",
        "\n",
        "The system uses a **cosine similarity threshold of 0.7** to classify whether a resume matches a job description.\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "We evaluate the recommendation system using the following metrics:\n",
        "- **Precision**: The proportion of relevant job descriptions among the recommended ones.\n",
        "- **Recall**: The proportion of relevant job descriptions retrieved.\n",
        "- **F1 Score**: The harmonic mean of precision and recall.\n",
        "- **Accuracy**: The overall correctness of the model in making recommendations.\n",
        "\n",
        "---\n",
        "\n",
        "## Visualization\n",
        "\n",
        "The distribution of cosine similarity scores is visualized using **seaborn** to observe how well the model differentiates between relevant and irrelevant job descriptions. A threshold line is drawn at `0.7` to separate relevant and irrelevant matches.\n",
        "\n",
        "---\n",
        "\n",
        "## Installation\n",
        "\n",
        "Follow the steps below to set up the project:\n",
        "\n",
        "### 1. Install required libraries:\n",
        "\n",
        "```bash\n",
        "!pip install sentence-transformers\n",
        "!pip install seaborn\n",
        "!pip install nltk\n",
        "```\n",
        "\n",
        "### 2. Download necessary NLTK datasets:\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "```\n",
        "\n",
        "### 3. Upload your datasets:\n",
        "\n",
        "Make sure the datasets `cleaned_internship_data.csv` and `cleaned_resumes.csv` are uploaded to your environment or local machine.\n",
        "\n",
        "---\n",
        "\n",
        "## Usage\n",
        "\n",
        "### 1. Load the datasets:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('cleaned_internship_data.csv')\n",
        "df2 = pd.read_csv('cleaned_resumes.csv')\n",
        "```\n",
        "\n",
        "### 2. Preprocess the text data:\n",
        "\n",
        "Use the `preprocess_text()` function to clean the data:\n",
        "\n",
        "```python\n",
        "df1['Cleaned_Job_Description'] = df1['Cleaned_Job_Description'].apply(preprocess_text)\n",
        "df2['Cleaned_Text'] = df2['Cleaned_Text'].apply(preprocess_text)\n",
        "```\n",
        "\n",
        "### 3. Encode the text using Sentence Transformers:\n",
        "\n",
        "```python\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "job_vectors = model.encode(df1['Cleaned_Job_Description'].dropna().tolist())\n",
        "resume_vectors = model.encode(df2['Cleaned_Text'].dropna().tolist())\n",
        "```\n",
        "\n",
        "### 4. Calculate the cosine similarity:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(resume_vectors, job_vectors)\n",
        "```\n",
        "\n",
        "### 5. Generate recommendations:\n",
        "\n",
        "```python\n",
        "top_n = 5\n",
        "recommendations = []\n",
        "\n",
        "for i, resume_vector in enumerate(resume_vectors):\n",
        "    similarities = similarity_matrix[i]\n",
        "    top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
        "    top_jobs = [df1['Cleaned_Job_Description'].tolist()[idx] for idx in top_indices]\n",
        "    recommendations.append(top_jobs)\n",
        "```\n",
        "\n",
        "### 6. Evaluate the results:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def evaluate_model(similarity_matrix, threshold=0.7):\n",
        "    y_true = [1] * len(similarity_matrix)  # All samples are relevant\n",
        "    y_pred = [1 if any(sim > threshold for sim in similarities) else 0 for similarities in similarity_matrix]\n",
        "    \n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "precision, recall, f1, accuracy = evaluate_model(similarity_matrix)\n",
        "```\n",
        "\n",
        "### 7. Visualize the similarity distribution:\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_similarity_distribution(similarity_scores, threshold=0.7):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(similarity_scores, bins=30, kde=True, color='b')\n",
        "    plt.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold ({threshold})')\n",
        "    plt.title(\"Distribution of Cosine Similarity Scores\", fontsize=16)\n",
        "    plt.xlabel(\"Cosine Similarity Score\", fontsize=12)\n",
        "    plt.ylabel(\"Frequency\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "visualize_similarity_distribution(similarity_matrix.flatten())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Contributing\n",
        "\n",
        "Contributions are always welcome! Feel free to open an issue or create a pull request for bug fixes, new features, or improvements.\n",
        "\n",
        "---\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.\n"
      ],
      "metadata": {
        "id": "PGSySonISWDT"
      }
    }
  ]
}